{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tabula"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file = r'file:///F:/WebScraping/Companies%20House%20co2/Example%20PDFs/companies_house_document%20(1).pdf'\n",
    "tables = tabula.read_pdf(file, pages = \"all\", multiple_tables = True)\n",
    "tables[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>2021\\rTonnes</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>36,914</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>43,656</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>67,474</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>148,044</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  2021\\rTonnes\n",
       "0       36,914\n",
       "1       43,656\n",
       "2       67,474\n",
       "3      148,044"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tables[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tabula.convert_into(file, \"annual-summary-and-sustainability-report-fy19_compressed.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "tables[1].to_csv(r'cr-2021-environment.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import tabula\n",
    "filepath_fil = r'C:\\Users\\jacks\\Documents\\Document(Offline)\\Barcanet\\Data Mining\\Data Mining Test 0.3\\Filtered'\n",
    "errors=[]\n",
    "directory_contents = os.listdir(filepath_fil)\n",
    "CompanyNames = [ x for x in directory_contents if \".txt\" not in x ]\n",
    "for companyFolder in CompanyNames:\n",
    "        folder = filepath_fil+'\\\\'+companyFolder\n",
    "        print(folder)\n",
    "        PDFs = os.listdir(folder)\n",
    "        print(PDFs)\n",
    "        for PDF in PDFs:\n",
    "                file = folder+'\\\\'+PDF\n",
    "                print(file)\n",
    "                try:\n",
    "                        tables = tabula.read_pdf(file, pages = \"all\", multiple_tables=True)\n",
    "                except ValueError:\n",
    "                        tables=[]\n",
    "                if tables:\n",
    "                        os.mkdir(file[:-4])\n",
    "                        for i in range(len(tables)):\n",
    "                                tables[i].to_csv(file[:-4]+'\\\\'+PDF[:-4]+' Table '+str(i)+'.csv',index=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pdf2image\n",
    "from pdf2image import convert_from_path\n",
    "\n",
    "pdfs = r\"F:\\WebScraping\\Companies House co2\\Example PDFs\\companies_house_document (1).pdf\"\n",
    "#pages = convert_from_path(pdfs, 350)\n",
    "\n",
    "filterPhrases = [\n",
    "    'Scope 1',\n",
    "    'Scope 2',\n",
    "    'Scope 3',\n",
    "    'scope 1',\n",
    "    'scope 2',\n",
    "    'scope 3',\n",
    "    'CO2',\n",
    "    'GHG',\n",
    "    'ghg'\n",
    "    \n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Filters PDFs down to the pages with key words on. These PDFs are scanned documents, and so cannot be searched using traditional PyPDF2 tool PDFReader\n",
    "\n",
    "Accepts list of PDFs. for each PDF, converts each page to image. Uses OCR to get text from image. scans text for key phrases. If any of the phrases are matched, it saves the page as a PDF.\n",
    "Once the whole PDF has been scanned, each saved page is added to a new PDF, and this PDF is then saved."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting Filter for:  02412526_aa_2021-12-07.pdf\n",
      "Filtered Pages =  []\n",
      "Data found in Page\n",
      "Number of Pages with Data found:  1\n",
      "Co2 Data Found\n",
      "0\n",
      "1\n",
      "using page\n",
      "Starting Filter for:  03118932_aa_2021-12-07.pdf\n",
      "Filtered Pages =  []\n",
      "Data found in Page\n",
      "Data found in Page\n",
      "Number of Pages with Data found:  2\n",
      "Co2 Data Found\n",
      "0\n",
      "1\n",
      "using page\n",
      "2\n",
      "3\n",
      "using page\n",
      "Starting Filter for:  03203080_aa_2021-12-07.pdf\n",
      "Filtered Pages =  []\n",
      "Number of Pages with Data found:  0\n",
      "No Co2 Data found\n",
      "Starting Filter for:  05867235_aa_2021-12-15.pdf\n",
      "Filtered Pages =  []\n",
      "Data found in Page\n",
      "Number of Pages with Data found:  1\n",
      "Co2 Data Found\n",
      "0\n",
      "1\n",
      "using page\n",
      "Starting Filter for:  07209034_aa_2021-12-20.pdf\n",
      "Filtered Pages =  []\n",
      "Data found in Page\n",
      "Number of Pages with Data found:  1\n",
      "Co2 Data Found\n",
      "0\n",
      "1\n",
      "using page\n",
      "Starting Filter for:  08012215_aa_2021-12-17.pdf\n",
      "Filtered Pages =  []\n",
      "Number of Pages with Data found:  0\n",
      "No Co2 Data found\n",
      "Starting Filter for:  08850452_aa_2021-12-08.pdf\n",
      "Filtered Pages =  []\n",
      "Data found in Page\n",
      "Number of Pages with Data found:  1\n",
      "Co2 Data Found\n",
      "0\n",
      "1\n",
      "using page\n",
      "Starting Filter for:  11322960_aa_2021-12-07.pdf\n",
      "Filtered Pages =  []\n",
      "Data found in Page\n",
      "Number of Pages with Data found:  1\n",
      "Co2 Data Found\n",
      "0\n",
      "1\n",
      "using page\n",
      "Starting Filter for:  11713253_aa_2021-12-20.pdf\n",
      "Filtered Pages =  []\n",
      "Data found in Page\n",
      "Number of Pages with Data found:  1\n",
      "Co2 Data Found\n",
      "0\n",
      "1\n",
      "using page\n",
      "Starting Filter for:  companies_house_document (1).pdf\n",
      "Filtered Pages =  []\n",
      "Data found in Page\n",
      "Number of Pages with Data found:  1\n",
      "Co2 Data Found\n",
      "0\n",
      "1\n",
      "using page\n",
      "Starting Filter for:  companies_house_document (10).pdf\n",
      "Filtered Pages =  []\n",
      "Data found in Page\n",
      "Data found in Page\n",
      "Number of Pages with Data found:  2\n",
      "Co2 Data Found\n",
      "0\n",
      "1\n",
      "using page\n",
      "2\n",
      "3\n",
      "using page\n",
      "Starting Filter for:  companies_house_document (11).pdf\n",
      "Filtered Pages =  []\n",
      "Data found in Page\n",
      "Number of Pages with Data found:  1\n",
      "Co2 Data Found\n",
      "0\n",
      "1\n",
      "using page\n",
      "Starting Filter for:  companies_house_document (12).pdf\n",
      "Filtered Pages =  []\n",
      "Data found in Page\n",
      "Number of Pages with Data found:  1\n",
      "Co2 Data Found\n",
      "0\n",
      "1\n",
      "using page\n",
      "Starting Filter for:  companies_house_document (13).pdf\n",
      "Filtered Pages =  []\n",
      "Data found in Page\n",
      "Data found in Page\n",
      "Number of Pages with Data found:  2\n",
      "Co2 Data Found\n",
      "0\n",
      "1\n",
      "using page\n",
      "2\n",
      "3\n",
      "using page\n",
      "Starting Filter for:  companies_house_document (14).pdf\n",
      "Filtered Pages =  []\n",
      "Data found in Page\n",
      "Data found in Page\n",
      "Number of Pages with Data found:  2\n",
      "Co2 Data Found\n",
      "0\n",
      "1\n",
      "using page\n",
      "2\n",
      "3\n",
      "using page\n",
      "Starting Filter for:  companies_house_document (15).pdf\n",
      "Filtered Pages =  []\n",
      "Data found in Page\n",
      "Number of Pages with Data found:  1\n",
      "Co2 Data Found\n",
      "0\n",
      "1\n",
      "using page\n",
      "Starting Filter for:  companies_house_document (16).pdf\n",
      "Filtered Pages =  []\n",
      "Data found in Page\n",
      "Data found in Page\n",
      "Number of Pages with Data found:  2\n",
      "Co2 Data Found\n",
      "0\n",
      "1\n",
      "using page\n",
      "2\n",
      "3\n",
      "using page\n",
      "Starting Filter for:  companies_house_document (17).pdf\n",
      "Filtered Pages =  []\n",
      "Data found in Page\n",
      "Number of Pages with Data found:  1\n",
      "Co2 Data Found\n",
      "0\n",
      "1\n",
      "using page\n",
      "Starting Filter for:  companies_house_document (18).pdf\n",
      "Filtered Pages =  []\n",
      "Data found in Page\n",
      "Data found in Page\n",
      "Number of Pages with Data found:  2\n",
      "Co2 Data Found\n",
      "0\n",
      "1\n",
      "using page\n",
      "2\n",
      "3\n",
      "using page\n",
      "Starting Filter for:  companies_house_document (19).pdf\n",
      "Filtered Pages =  []\n",
      "Data found in Page\n",
      "Data found in Page\n",
      "Number of Pages with Data found:  2\n",
      "Co2 Data Found\n",
      "0\n",
      "1\n",
      "using page\n",
      "2\n",
      "3\n",
      "using page\n",
      "Starting Filter for:  companies_house_document (2).pdf\n",
      "Filtered Pages =  []\n",
      "Data found in Page\n",
      "Number of Pages with Data found:  1\n",
      "Co2 Data Found\n",
      "0\n",
      "1\n",
      "using page\n",
      "Starting Filter for:  companies_house_document (20).pdf\n",
      "Filtered Pages =  []\n",
      "Data found in Page\n",
      "Number of Pages with Data found:  1\n",
      "Co2 Data Found\n",
      "0\n",
      "1\n",
      "using page\n",
      "Starting Filter for:  companies_house_document (21).pdf\n",
      "Filtered Pages =  []\n",
      "Data found in Page\n",
      "Number of Pages with Data found:  1\n",
      "Co2 Data Found\n",
      "0\n",
      "1\n",
      "using page\n",
      "Starting Filter for:  companies_house_document (22).pdf\n",
      "Filtered Pages =  []\n",
      "Data found in Page\n",
      "Number of Pages with Data found:  1\n",
      "Co2 Data Found\n",
      "0\n",
      "1\n",
      "using page\n",
      "Starting Filter for:  companies_house_document (23).pdf\n",
      "Filtered Pages =  []\n",
      "Data found in Page\n",
      "Data found in Page\n",
      "Number of Pages with Data found:  2\n",
      "Co2 Data Found\n",
      "0\n",
      "1\n",
      "using page\n",
      "2\n",
      "3\n",
      "using page\n",
      "Starting Filter for:  companies_house_document (24).pdf\n",
      "Filtered Pages =  []\n",
      "Data found in Page\n",
      "Number of Pages with Data found:  1\n",
      "Co2 Data Found\n",
      "0\n",
      "1\n",
      "using page\n",
      "Starting Filter for:  companies_house_document (25).pdf\n",
      "Filtered Pages =  []\n",
      "Data found in Page\n",
      "Data found in Page\n",
      "Number of Pages with Data found:  2\n",
      "Co2 Data Found\n",
      "0\n",
      "1\n",
      "using page\n",
      "2\n",
      "3\n",
      "using page\n",
      "Starting Filter for:  companies_house_document (26).pdf\n",
      "Filtered Pages =  []\n",
      "Data found in Page\n",
      "Number of Pages with Data found:  1\n",
      "Co2 Data Found\n",
      "0\n",
      "1\n",
      "using page\n",
      "Starting Filter for:  companies_house_document (27).pdf\n",
      "Filtered Pages =  []\n",
      "Data found in Page\n",
      "Number of Pages with Data found:  1\n",
      "Co2 Data Found\n",
      "0\n",
      "1\n",
      "using page\n",
      "Starting Filter for:  companies_house_document (28).pdf\n",
      "Filtered Pages =  []\n",
      "Data found in Page\n",
      "Number of Pages with Data found:  1\n",
      "Co2 Data Found\n",
      "0\n",
      "1\n",
      "using page\n",
      "Starting Filter for:  companies_house_document (3).pdf\n",
      "Filtered Pages =  []\n",
      "Data found in Page\n",
      "Number of Pages with Data found:  1\n",
      "Co2 Data Found\n",
      "0\n",
      "1\n",
      "using page\n",
      "Starting Filter for:  companies_house_document (4).pdf\n",
      "Filtered Pages =  []\n",
      "Data found in Page\n",
      "Number of Pages with Data found:  1\n",
      "Co2 Data Found\n",
      "0\n",
      "1\n",
      "using page\n",
      "Starting Filter for:  companies_house_document (5).pdf\n",
      "Filtered Pages =  []\n",
      "Data found in Page\n",
      "Number of Pages with Data found:  1\n",
      "Co2 Data Found\n",
      "0\n",
      "1\n",
      "using page\n",
      "Starting Filter for:  companies_house_document (6).pdf\n",
      "Filtered Pages =  []\n",
      "Data found in Page\n",
      "Number of Pages with Data found:  1\n",
      "Co2 Data Found\n",
      "0\n",
      "1\n",
      "using page\n",
      "Starting Filter for:  companies_house_document (7).pdf\n",
      "Filtered Pages =  []\n",
      "Data found in Page\n",
      "Number of Pages with Data found:  1\n",
      "Co2 Data Found\n",
      "0\n",
      "1\n",
      "using page\n",
      "Starting Filter for:  companies_house_document (8).pdf\n",
      "Filtered Pages =  []\n",
      "Data found in Page\n",
      "Number of Pages with Data found:  1\n",
      "Co2 Data Found\n",
      "0\n",
      "1\n",
      "using page\n",
      "Starting Filter for:  companies_house_document (9).pdf\n",
      "Filtered Pages =  []\n",
      "Data found in Page\n",
      "Number of Pages with Data found:  1\n",
      "Co2 Data Found\n",
      "0\n",
      "1\n",
      "using page\n",
      "Starting Filter for:  companies_house_document.pdf\n",
      "Filtered Pages =  []\n",
      "Data found in Page\n",
      "Number of Pages with Data found:  1\n",
      "Co2 Data Found\n",
      "0\n",
      "1\n",
      "using page\n",
      "Starting Filter for:  environmental-social-and-governance-data-kpi-2020-and-assurance-statement.pdf\n",
      "Filtered Pages =  []\n",
      "Data found in Page\n",
      "Data found in Page\n",
      "Number of Pages with Data found:  2\n",
      "Co2 Data Found\n",
      "0\n",
      "1\n",
      "using page\n",
      "2\n",
      "3\n",
      "using page\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import pdf2image\n",
    "from pdf2image import convert_from_path\n",
    "from PIL import Image\n",
    "import pytesseract\n",
    "from fpdf import FPDF\n",
    "from PyPDF4 import PdfFileReader, PdfFileWriter\n",
    "\n",
    "pytesseract.pytesseract.tesseract_cmd = r'C:\\Program Files\\Tesseract-OCR\\tesseract.exe'\n",
    "PDFs = os.listdir(r'F:\\WebScraping\\Companies House co2\\Example PDFs')\n",
    "filterPhrases = [\n",
    "    'Scope 1',\n",
    "    'Scope 2',\n",
    "    'Scope 3',\n",
    "    'scope 1',\n",
    "    'scope 2',\n",
    "    'scope 3',\n",
    "    'CO2',\n",
    "    'GHG',\n",
    "    'ghg'\n",
    "]\n",
    "\n",
    "for pdfName in PDFs:\n",
    "    filteredPages = []\n",
    "    pages = convert_from_path(r'F:\\WebScraping\\Companies House co2\\Example PDFs\\\\'+pdfName, 350)\n",
    "    print('Starting Filter for: ',pdfName)\n",
    "    print('Filtered Pages = ',filteredPages)\n",
    "    for page in pages:\n",
    "        page.save('out.jpg','JPEG')\n",
    "        image = cv2.imread('out.jpg')\n",
    "        text = str(pytesseract.image_to_string(image))\n",
    "        if any(word in text for word in filterPhrases):\n",
    "            filteredPages.append(image)\n",
    "            print('Data found in Page')\n",
    "    print('Number of Pages with Data found: ',len(filteredPages))\n",
    "    if not filteredPages:\n",
    "        print('No Co2 Data found')\n",
    "    else:\n",
    "        print('Co2 Data Found')\n",
    "        pdf = FPDF()\n",
    "        for page in filteredPages:\n",
    "            image = Image.fromarray(page)\n",
    "            image.save(\"out.jpg\")\n",
    "            #page.save('out.jpg','JPEG')\n",
    "            pdf.add_page()\n",
    "            #print(page)\n",
    "            pdf.image('out.jpg',x = None, y = None, w = 210, h = 297, type = '', link = '')\n",
    "        outputFile = r\"F:\\WebScraping\\Companies House co2\\outputs\\\\\"+pdfName\n",
    "        pdf.output(outputFile, \"F\")\n",
    "        '''\n",
    "        The way the image is exported to a PDF, for each page a redundant blank page is produced (the create the PDF in the first place)\n",
    "        This is an are to improve, and is fixed in the following section which is inefficient\n",
    "        '''\n",
    "        number_of_pages = len(filteredPages*2)\n",
    "\n",
    "\n",
    "        output_writer = PdfFileWriter()\n",
    "        pdfOne = PdfFileReader(outputFile)\n",
    "\n",
    "        for i in list(range(0, number_of_pages)):\n",
    "            print(i)\n",
    "            if i % 2 != 0:\n",
    "                print('using page')\n",
    "                page = pdfOne.getPage(i)\n",
    "                output_writer.addPage(page)\n",
    "\n",
    "        with open(outputFile, \"wb\") as outfile:\n",
    "            output_writer.write(outfile)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "using page\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import pdf2image\n",
    "from pdf2image import convert_from_path\n",
    "from PIL import Image\n",
    "import pytesseract\n",
    "from fpdf import FPDF\n",
    "from PyPDF4 import PdfFileReader, PdfFileWriter\n",
    "outputFile = r\"F:\\WebScraping\\Companies House co2\\Outputs\\03118932_aa_2021-12-07.pdf\"\n",
    "filteredPages=[2]\n",
    "'''\n",
    "The way the image is exported to a PDF, for each page a redundant blank page is produced (the create the PDF in the first place)\n",
    "This is an are to improve, and is fixed in the following section which is inefficient\n",
    "'''\n",
    "number_of_pages = len(filteredPages*2)\n",
    "\n",
    "\n",
    "output_writer = PdfFileWriter()\n",
    "pdfOne = PdfFileReader(outputFile)\n",
    "\n",
    "for i in list(range(0, number_of_pages)):\n",
    "    print(i)\n",
    "    if i % 2 != 0:\n",
    "        print('using page')\n",
    "        page = pdfOne.getPage(i)\n",
    "        output_writer.addPage(page)\n",
    "\n",
    "with open(outputFile, \"wb\") as outfile:\n",
    "    output_writer.write(outfile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "4c6ca264d172b24b4c025b0dcbb0d6fd1f3cbe68af6d1a1e53410e66c73beeb8"
  },
  "kernelspec": {
   "display_name": "Python 3.7.7 64-bit ('env': venv)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
